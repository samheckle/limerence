{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9141715d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 15:00:06.418730: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62e1c540",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(\"2try.txt\").read()\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9cea62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = list(doc.sents)\n",
    "words = [w for w in list(doc) if w.is_alpha]\n",
    "noun_chunks = list(doc.noun_chunks)\n",
    "entities = list(doc.ents)\n",
    "times = [e for e in entities if e.label_ == \"TIME\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66306086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it\n",
      "\n",
      "the right\n",
      "\n",
      "me\n",
      "\n",
      "mere acceptance\n",
      "\n",
      "a cradle\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "for item in random.sample(noun_chunks, 5):\n",
    "    print(item.text.strip().replace(\"\\n\", \" \"))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5ae02b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "that morning\n",
      "one afternoon\n",
      "the last few minutes\n",
      "midnight\n",
      "the minutes\n",
      "night\n",
      "hours\n",
      "a few hours\n",
      "the same hour every day\n",
      "one minute\n",
      "a minute\n",
      "that morning\n",
      "the hour\n",
      "the night\n",
      "afternoon\n",
      "THE HOUR\n",
      "the hour\n",
      "this minute\n"
     ]
    }
   ],
   "source": [
    "for item in random.sample(times, 18): # change \"times\" to \"people\" or \"locations\" to sample those lists\n",
    "    print(item.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d5077cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_subtree(st):\n",
    "    return ''.join([w.text_with_ws for w in list(st)]).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7b9d97b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prep_phrases = []\n",
    "for word in doc:\n",
    "    if word.dep_ == 'prep':\n",
    "        prep_phrases.append(flatten_subtree(word.subtree).replace(\"\\n\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f446821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['of tiny unavowable interdictions',\n",
       " 'on a stool',\n",
       " 'of Action',\n",
       " 'by being written',\n",
       " 'in this simple transition from I',\n",
       " 'of driv\\xad ing out the image or of being identified with it',\n",
       " 'of his passion',\n",
       " 'in movement',\n",
       " 'of his own site',\n",
       " 'of the other',\n",
       " 'Throughout life',\n",
       " 'In the other\\'s perfect and \"embalmed\" figure',\n",
       " 'of the \"charming body',\n",
       " 'in his mind',\n",
       " 'down his face',\n",
       " 'of investiga\\xad tion',\n",
       " 'of knowledge (scientia',\n",
       " 'but a generalized suasion',\n",
       " 'At times',\n",
       " 'by semantic necessity',\n",
       " 'for his patient (or else',\n",
       " 'of values',\n",
       " 'of universal neurosis',\n",
       " \"to the loved being who receives the intruder's demand without seeming to suffer from it\",\n",
       " 'of tyrannies',\n",
       " 'by the conversations she has with the Beast',\n",
       " 'for',\n",
       " 'of melancholy',\n",
       " 'in Arabic',\n",
       " 'to some sanction',\n",
       " 'in doubt',\n",
       " 'to this subject',\n",
       " 'upon it',\n",
       " 'in truth',\n",
       " 'of a blank word',\n",
       " 'of total union',\n",
       " \"from a constraint in the lover's discourse\",\n",
       " 'by desire',\n",
       " 'out of a thousand',\n",
       " 'far from human things',\n",
       " 'of speech',\n",
       " 'to silen.t expenditure',\n",
       " 'before a sunrise',\n",
       " 'of the rumor',\n",
       " 'of love-as-passion',\n",
       " 'of corruption',\n",
       " 'in the presence of my confidant:',\n",
       " 'of love',\n",
       " 'of information',\n",
       " 'upon anything',\n",
       " 'of infor\\xad mation, its interests and initiatives',\n",
       " 'with whom',\n",
       " 'by minor conflic\\xad tive interventions',\n",
       " 'in a cold and astonished fashion',\n",
       " 'as force-against other forces',\n",
       " 'of the wood',\n",
       " 'in which',\n",
       " 'of a hero who does not speak before dying',\n",
       " 'of its inmates',\n",
       " 'to the avowal',\n",
       " 'with the loved being',\n",
       " 'to which',\n",
       " 'of absence and withdrawal of reality',\n",
       " 'of someone speaking within himself',\n",
       " 'as a final offense',\n",
       " 'to me',\n",
       " 'by con\\xad verse vocation',\n",
       " 'of logic',\n",
       " 'of ribbon',\n",
       " 'of festival',\n",
       " 'Between the two of us now',\n",
       " 'as an artist',\n",
       " \"in the other's fashion\",\n",
       " 'in his voice',\n",
       " 'of this anxiety',\n",
       " 'by feigning to renounce him',\n",
       " 'to another woman',\n",
       " 'with friends',\n",
       " 'without memory',\n",
       " 'by pulling on the string',\n",
       " 'of the year',\n",
       " 'of effort',\n",
       " 'with the ebb which has filled it with itself',\n",
       " 'in himself',\n",
       " 'by offering the ego the reward of remaining alive',\n",
       " 'into some generalized revulsion: a crying jag ( for instance)',\n",
       " 'of gregarity',\n",
       " 'to my own philosophy',\n",
       " 'in this subject',\n",
       " 'without a crisis',\n",
       " 'since Christianity',\n",
       " 'to him',\n",
       " 'into yours',\n",
       " 'in love-as-passion, a fragment of real',\n",
       " 'of love',\n",
       " 'in the dinner',\n",
       " 'of the shoulders',\n",
       " 'By a singular logic',\n",
       " 'of language itself',\n",
       " 'from Ignatius of Loyola']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(prep_phrases, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "49f49330",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = [flatten_subtree(word.subtree).replace(\"\\n\", \" \")\n",
    "            for word in doc if word.dep_ in ('nsubj', 'nsubjpass')]\n",
    "past_tense_verbs = [word.text for word in words if word.tag_ == 'VBD' and word.lemma_ != 'be']\n",
    "adjectives = [word.text for word in words if word.tag_.startswith('JJ')]\n",
    "nouns = [word.text for word in words if word.tag_.startswith('NN')]\n",
    "prep_phrases = [flatten_subtree(word.subtree).replace(\"\\n\", \" \")\n",
    "                for word in doc if word.dep_ == 'prep']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a703e0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tracery\n",
    "import textwrap\n",
    "from tracery.modifiers import base_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "13da7246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'On the dirty cobble stones, you known.'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules = {\n",
    "    \"origin\": [\n",
    "        #\"#subject.capitalize# #predicate#.\",\n",
    "        #\"#subject.capitalize# #predicate#.\",\n",
    "        \"#prepphrase.capitalize#, you #predicate#.\"\n",
    "    ],\n",
    "    \"predicate\": [\n",
    "        \"#verb#\",\n",
    "        \"#verb# #nounphrase#\",\n",
    "        \"#verb# #prepphrase#\"\n",
    "    ],\n",
    "    \"nounphrase\": [\n",
    "        \"the #noun#\",\n",
    "        \"the #adj# #noun#\",\n",
    "        \"the #noun# #prepphrase#\",\n",
    "        \"the #noun# and the #noun#\",\n",
    "        \"#noun.a#\",\n",
    "        \"#noun-chunks.a#\",\n",
    "        \"#adj.a# #noun#\",\n",
    "        \"the #noun# that #predicate#\"\n",
    "    ],\n",
    "    \"verb\": past_tense_verbs,\n",
    "    \"noun\": nouns,\n",
    "    \"noun-chunks\": noun_chunks,\n",
    "    \"adj\": adjectives,\n",
    "    \"prepphrase\": prep_phrases\n",
    "}\n",
    "grammar = tracery.Grammar(rules)\n",
    "grammar.add_modifiers(base_english)\n",
    "grammar.flatten(\"#origin#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d567fa77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About me who am unknown to myself, you said to the grass. On\n",
      "his desk, you remembered of words. To ask, you thought the\n",
      "image that had. On, you heard with the girl. With the\n",
      "picture of the young Greta Garbo, you changed. As a form of\n",
      "knowledge, you distinguished. Into the air, you said. Of the\n",
      "lame adventures of a girl in a city that’s entirely against\n",
      "her, you belonged. In beds, you transformed to her. Like us,\n",
      "you turned. For taking up space, you did. In sloooow motion,\n",
      "you did.\n"
     ]
    }
   ],
   "source": [
    "from textwrap import fill\n",
    "output = \" \".join([grammar.flatten(\"#origin#\") for i in range(12)])\n",
    "#print(fill(output, 60))\n",
    "print(textwrap.fill(output, 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ce41c381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a while, you looked. Into organic simplicity, you had. On\n",
      "that morning of May seventh, you thought. Of the room\n",
      "without the Marias, you had with her flimsy pillow. From\n",
      "dying, you stammered in everything that existed and\n",
      "everything that didn’t exist too. Since what I’m saying, you\n",
      "distinguished. On a single arm, you slept just for her. Of\n",
      "all, you asked the girlfriend. Of the abstract Being who\n",
      "gives and takes, you came a word. In a peal of neighing, you\n",
      "wanted an essential liver. During the day, you did a giant\n",
      "dreams. Of raw meat, you told of absolute courage.\n"
     ]
    }
   ],
   "source": [
    "from textwrap import fill\n",
    "output = \" \".join([grammar.flatten(\"#origin#\") for i in range(12)])\n",
    "#print(fill(output, 60))\n",
    "print(textwrap.fill(output, 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "bad681df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You thought in the metal factory.'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules = {\n",
    "    \"origin\": [\n",
    "#         \"#prepphrase#\",\n",
    "#         \"#predicate#.a#\",\n",
    "        \"#prepphrase.capitalize#, you #predicate#.\",\n",
    "        \"You #predicate# #prepphrase#.\"\n",
    "    ],\n",
    "    \"predicate\": [\n",
    "        \"#verb#\",\n",
    "        \"#verb# #nounphrase#\",\n",
    "        \"#verb# #prepphrase#\"\n",
    "    ],\n",
    "    \"nounphrase\": [\n",
    "        \"the #noun#\",\n",
    "        \"the #adj# #noun#\",\n",
    "        \"the #noun# #prepphrase#\",\n",
    "        \"the #noun# and the #noun#\",\n",
    "        \"#noun.a#\",\n",
    "        \"#noun-chunks.a#\",\n",
    "        \"#adj.a# #noun#\",\n",
    "        \"the #noun# that #predicate#\"\n",
    "    ],\n",
    "    \"verb\": past_tense_verbs,\n",
    "    \"noun\": nouns,\n",
    "    \"noun-chunks\": noun_chunks,\n",
    "    \"adj\": adjectives,\n",
    "    \"prepphrase\": prep_phrases\n",
    "}\n",
    "grammar = tracery.Grammar(rules)\n",
    "grammar.add_modifiers(base_english)\n",
    "grammar.flatten(\"#origin#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "78725029",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We mattered from charcoal. We expected. You fled the men and\n",
      "the connection. We considered OF THE STAR. Of her life, you\n",
      "threw amongst the drops of time. With her daily unreality,\n",
      "you believed. With the minimum of goodness, you seized to my\n",
      "mystery. You wanted the culture that slept at a girl like\n",
      "you. You let. We worked ma’am. We looked. Into heaven, you\n",
      "dumped of love.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/xg/1hkzm31x74nf_39146wrvmw00000gn/T/ipykernel_19133/1761581408.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mexport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtextwrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexport\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "from textwrap import fill\n",
    "output = \" \".join([grammar.flatten(\"#origin#\") for i in range(12)])\n",
    "\n",
    "export = print(textwrap.fill(output, 60))\n",
    "for line in export:\n",
    "    words = line.split() \n",
    "    outputs = [] \n",
    "    sel = random.sample(words, random.randint(0,len(words)))\n",
    "    \n",
    "    for item in words:\n",
    "        if item in sel:\n",
    "            outputs.append(item)\n",
    "        for char in item:\n",
    "            outputs.append('.')\n",
    "    print(textwrap.fill(''.join(export), 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a86297b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You used on the hem of her underwear for who knows what.\n",
      "With her, you danced. You thought As for the girl of my\n",
      "Maca. Of desire, you made On that morning of May seventh.\n",
      "For the day, you did.\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "from textwrap import fill\n",
    "output = \"\\n\".join([grammar.flatten(\"#origin#\") for i in range(5)])\n",
    "print(textwrap.fill(output, 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0c697ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "width                - 40\n",
      "expand_tabs          - True\n",
      "tabsize              - 4\n",
      "replace_whitespace   - True\n",
      "drop_whitespace      - True\n",
      "initial_indent       - \n",
      "subsequent_indent    - \n",
      "fix_sentence_endings - True\n",
      "break_long_words     - False\n",
      "break_on_hyphens     - False\n",
      "max_lines            - 12\n",
      "placeholder          -   [..Continued]\n",
      "\n",
      "The Zen of Python, by Tim Peters.\n",
      "Beautiful is better than ugly.  Explicit\n",
      "is better than implicit.  Simple is\n",
      "better than complex.  Complex is better\n",
      "than complicated.  Flat is better than\n",
      "nested.  Sparse is better than dense.\n",
      "Readability counts.  Special cases\n",
      "aren't special enough to break the\n",
      "rules.  Although practicality beats\n",
      "purity.  Errors should never pass\n",
      "silently.  Unless explicitly silenced.\n",
      "In the face of ambiguity,  [..Continued]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87482143",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
